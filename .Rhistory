f21 <- function(t){
return(2*(t-0.5)^2 - t*0.3)
}
f22 <- function(t){
return(0.2 -0.3*t + 0.1*cos(8*t))
}
# Simulation of the Input Variables :
X1 <- NULL
X2 <- NULL
#beta <- rnorm(n,1, 0.2) # Dilatation terms
beta <- rnorm(n,1,disp)
theta <- runif(n,min=0,max=Hshift)
mu <- rnorm(n, 0, Vshift)
for (i in 1:n){
X1 <- c(X1,beta[i]*((G1[i]==1)*f11(time+theta[i])+(G1[i]==0)*f12(time+theta[i])))
X2 <- c(X2,beta[i]*((G2[i]==1)*f21(time+theta[i])+(G2[i]==0)*f22(time+theta[i])))
}
X1 <- X1+ rnorm(length(X1), 0,0.02) # We add some noise
X2 <- X2+ rnorm(length(X2), 0,0.02) # We add some noise
X <- data.frame(X1,X2) # Data matrix
# Define the timepical temporal behavior functions g.,. for the Output :
g11 <- function(t){
return(t+ 0.3*sin(10*(t+1)))
}
g12<- function(t){
return(t+2*(t-0.7)^2)
}
g21 <- function(t){
return(1.5*exp(-(t-0.5)^2/0.5)- 0.1*(t+1)*cos(10*t))
}
g22 <- function(t){
return(log(13*(t+0.1))/(1+t))
}
# Output simulation :
Y <- NULL
groupes <- 1*(G1==0 & G2==0) + 2*(G1==1 & G2==0) + 3*(G1==1 & G2==1) +  4*(G1==0 & G2==1)
for (i in 1:n){
Y <- c(Y,mu[i]+ beta[i]*((G1[i]==1 & G2[i]==0)*(g11(time+theta[i]))+ (G1[i]==1 & G2[i]==1)*(g12(time+theta[i] )) + (G1[i]==0 & G2[i]==1)*(g21(time+theta[i])) + (G1[i]==0 & G2[i]==0)*(g22(time+theta[i]))))
}
Y <- Y+ rnorm(length(Y), 0, 0.1) # We add some noise
if (affiche==TRUE){
par(mfrow=c(1,3))
w <- which(id==1)
plot(time,X[w,1], type="l", ylim=c(min(X[,1]), max(X[,1])), col="grey",ylab="", xlab="time", main="Input variable X1")
for (i in 2:n){
w <- which(id==i)
lines(time,X[w,1],col="grey")
}
w <- which(id==1)
plot(time,X2[w], type="l", ylim=c(min(X2), max(X2)), col="grey", ylab="", xlab="time", main="Input variable X2")
for (i in 2:n){
w <- which(id==i)
lines(time,X2[w], col="grey")
}
#X11(height = 4,width = 5)
#par(mar=c(4,2,1,1))
w <- which(id==1)
plot(time,Y[w], type="l", ylim=c(min(Y), max(Y)), col="grey", xlab="time", ylab="", main = "Output variable Y")
for (i in 1:n){
w <- which(id==i)
lines(time,Y[w], col="grey")
}
#time1 <- seq(0,1,0.01)
#lines(time1,g11(time1), col=1,type="l", lwd=2)
#lines(time1,g12(time1), col=2,type="l",lwd=2)
#lines(time1,g21(time1), col=3,type="l",lwd=2)
#lines(time1,g22(time1), col=4,type="l",lwd=2)
#legend("bottomright",c("g00","g01","g10",'g11'), col=c(1,2,3,4), lwd=c(2,2,2,2))
par(mfrow=c(1,1))}
## ON va construire nos différentes formes pour l'apprentissage ::
formes1 <- factor(rep(NA,n),levels=c("triangle","rectangle","cercle", "poisson"))
formes2 <- factor(rep(NA,n), levels=c("triangle","rectangle","cercle","poisson"))
formes3 <- factor(rep(NA,n), levels=c("triangle","rectangle","cercle","poisson"))
# Maintenant il nous faut remplir les vecteurs formes1 et formes2
formes1[which(G1==0)] <- "poisson"
formes1[which(G1==1)] <- "cercle"
formes2[which(G2==0)] <- "triangle"
formes2[which(G2==1)] <- "rectangle"
formes3 <- sample(c("triangle","rectangle","cercle","poisson"),n,replace = TRUE)
# Il nous faut maintenant remplis un array
Shape <- array(0,dim=c(Nshape,2,n,3))
homot <- runif(n, 1,2.5)
translaX <- runif(n,-20,20)
translaY <- runif(n,-20,20)
rot <- runif(n)*2*pi
Rot <- matrix(c(cos(rot),sin(rot),-sin(rot),cos(rot)),2,2)
minX1 <- rep(NA,n)
maxX1 <- rep(NA,n)
minY1 <- rep(NA,n)
maxY1 <- rep(NA,n)
minX2 <- rep(NA,n)
maxX2 <- rep(NA,n)
minY2 <- rep(NA,n)
maxY2 <- rep(NA,n)
for (i in 1:n){
Shape[,,i,1] <- Shape[,,i,1]+homot[i]*(triangle(Nshape)*(formes1[i]=="triangle"))
Shape[,,i,1] <- Shape[,,i,1]+homot[i]*(rectangle(Nshape)*(formes1[i]=="rectangle"))
Shape[,,i,1] <- Shape[,,i,1]+homot[i]*(Cercle(Nshape)*(formes1[i]=="cercle"))
Shape[,,i,1] <- Shape[,,i,1]+homot[i]*(poisson(Nshape)*(formes1[i]=="poisson"))
Shape[,,i,2] <- Shape[,,i,2]+homot[i]*(triangle(Nshape)*(formes2[i]=="triangle"))
Shape[,,i,2] <- Shape[,,i,2]+homot[i]*(rectangle(Nshape)*(formes2[i]=="rectangle"))
Shape[,,i,2] <- Shape[,,i,2]+homot[i]*(Cercle(Nshape)*(formes2[i]=="cercle"))
Shape[,,i,2] <- Shape[,,i,2]+homot[i]*(poisson(Nshape)*(formes2[i]=="poisson"))
Shape[,,i,3] <- Shape[,,i,3]+homot[i]*(triangle(Nshape)*(formes3[i]=="triangle"))
Shape[,,i,3] <- Shape[,,i,3]+homot[i]*(rectangle(Nshape)*(formes3[i]=="rectangle"))
Shape[,,i,3] <- Shape[,,i,3]+homot[i]*(Cercle(Nshape)*(formes3[i]=="cercle"))
Shape[,,i,3] <- Shape[,,i,3]+homot[i]*(poisson(Nshape)*(formes3[i]=="poisson"))
Shape[,1,i,1] <- translaX[i]+Shape[,1,i,1]
Shape[,2,i,1] <- translaY[i]+Shape[,2,i,1]
Shape[,1,i,2] <- translaX[i]+Shape[,1,i,2]
Shape[,2,i,2] <- translaY[i]+Shape[,2,i,2]
Shape[,1,i,3] <- translaX[i]+Shape[,1,i,3]
Shape[,2,i,3] <- translaY[i]+Shape[,2,i,3]
Rot <- matrix(c(cos(rot[i]),sin(rot[i]),-sin(rot[i]),cos(rot[i])),2,2)
for (j in 1:(dim(Shape[,,i,1])[1])){
Shape[j,,i,1] <- Rot%*%Shape[j,,i,1]
Shape[j,,i,2] <- Rot%*%Shape[j,,i,2]
}
minX1[i] <- min(Shape[,1,i,1])
maxX1[i] <- max(Shape[,1,i,1])
minY1[i] <- min(Shape[,2,i,1])
maxY1[i] <- max(Shape[,2,i,1])
minX2[i] <- min(Shape[,1,i,2])
maxX2[i] <- max(Shape[,1,i,2])
minY2[i] <- min(Shape[,2,i,2])
maxY2[i] <- max(Shape[,2,i,2])
}
Shape <- list(X=Shape,id=unique(id))
## On va construire la matrice des différentes images ::
Images <- array(0,dim=c(nrow(IM[,,1]),ncol(IM[,,1]),n,3))
for (i in 1:n){
Images[,,i,1] <- (IM[,,sample(which(Ytrain==5),1)])*(G1[i]==0)+(IM[,,sample(which(Ytrain==8),1)])*(G1[i]==1)
Images[,,i,2] <- IM[,,sample(c(which(Ytrain==5),which(Ytrain==6),which(Ytrain==7),which(Ytrain==8)),1)]
Images[,,i,3] <- IM[,,sample(c(which(Ytrain==6),which(Ytrain==8),which(Ytrain==1),which(Ytrain==2)),1)]
}
Images <- list(X=Images,id=unique(id))
# On va créer des facteurs ::
fact1 <- factor(rep(NA,length(beta)), levels=c("a","b","c","d"))
fact1[which(beta<=1-sd(beta))] <- "a"
fact1[intersect(which(beta>1-sd(beta)),which(beta<=1))] <- "b"
fact1[intersect(which(beta>1),which(beta<=1.5))] <- "c"
fact1[ which(beta>1+sd(beta))] <- "d"
#fact1[G1==0] <- "a"
#fact1[G1==1] <- "b"
#fact1[G2==0] <- "c"
#fact1[G2==1] <- "d"
fact2 <- factor(rep(NA,length(theta)), levels=c("e","f"))
fact2[which(theta<=Hshift/2)] <- "e"
fact2[ which(theta>Hshift/2)] <- "f"
fact3 <- factor(rep(NA,length(mu)), levels=c("g","h","i","j"))
fact3[which(mu<=-sd(mu))] <- "g"
fact3[intersect(which(mu>-sd(mu)),which(mu<=0))] <- "h"
fact3[intersect(which(mu>0),which(mu<=sd(mu)))] <- "i"
fact3[ which(mu>sd(mu))] <- "j"
Factor <- list(X=data.frame(fact1,fact2, fact3), id =unique(id))
#### On va perturber les scalaires : beta theta et mu : On va garder ça comme ça
beta_prime <- beta + rnorm(n,0,disp/scalar.perturb)
theta_prime <- theta + rnorm(n,0,Hshift/scalar.perturb)
mu_prime <- mu + rnorm(n,0, Vshift/scalar.perturb)
#### Ok pour ça
Scalar.bruit = list(X=cbind(beta_prime,theta_prime,mu_prime),id=unique(id))
Scalar.pur=list(X=cbind(beta,theta,mu),id=unique(id))
Curves <- list(X=X,id=id, time=rep(time,n))
Y <- list(type="curve",Y=Y,id=id,time=rep(time,n))
return(list(Curve=Curves,Scalar.pur=Scalar.pur,Scalar.bruit=Scalar.bruit,Factor=Factor,Shape=Shape,Image=Images,Y=Y))
}
data <- DataGenCurves5(n=100,disp = 0.3,Vshift = 0.01,Hshift = 0.1,scalar.perturb = 2, Nshape = 50,affiche=TRUE)
Y <- list(type="image", Y=data$Image$X[,,,1], id=data$Image$id)
Curve <-list(type="curve",X=data$Curve$X, id=data$Curve$id, time=data$Curve$time)
devtools::load_all("C:/Users/Saint Louis/Desktop/FrechForest")
devtools::load_all("C:/Users/Saint Louis/Desktop/FrechForest")
#### code pour l'élagage :::
branche <- function(tree, t){
Y <- list()
f <- unique(tree$feuilles)
sous_split <- tree$V_split[which(tree$V_split[,2]==t),]
N <- 2
g <- which(tree$V_split[,2]==2*t)
d <- which(tree$V_split[,2]==2*t+1)
noeuds_courants <- as.numeric(as.character(tree$V_split[c(g,d),2]))
noeuds_courants1 <- noeuds_courants
sous_split <- rbind(sous_split, tree$V_split[c(g,d),])
sous_feuilles <- NULL
hist_nodes <- list()
if (length(g)>0) {hist_nodes[[2*t]] <- tree$hist_nodes[[2*t]]}
if (length(d)>0) {hist_nodes[[2*t+1]] <- tree$hist_nodes[[2*t+1]]}
if (length(d)== 0) {sous_feuilles <- c(sous_feuilles, 2*t+1)
Y[[2*t+1]] <- tree$Y_pred[[2*t+1]]}
if (length(g)== 0) {sous_feuilles <- c(sous_feuilles, 2*t)
Y[[2*t]] <- tree$Y_pred[[2*t]]}
racine <- t
if (length(noeuds_courants)>0) {
while(N>0){
p <- 0
courant_prime <- NULL
for (l in noeuds_courants){
g <- which(tree$V_split[,2]==2*l)
d <- which(tree$V_split[,2]==2*l+1)
if (length(g)>0){ p <- p+2
courant_prime <- c(courant_prime, as.numeric(as.character(tree$V_split[g,2])))
sous_split <- rbind(sous_split, tree$V_split[g,])
hist_nodes[[2*l]] <- tree$hist_nodes[[2*l]]}
if (length(d)>0){ p <- p+2
courant_prime <- c(courant_prime, as.numeric(as.character(tree$V_split[d,2])))
sous_split <- rbind(sous_split, tree$V_split[d,])
hist_nodes[[2*l+1]] <- tree$hist_nodes[[2*l+1]]}
if(length(g)==0) {sous_feuilles <- c(sous_feuilles,2*l)
Y[[2*l]] <- tree$Y_pred[[2*l]]}
if (length(d)==0) { sous_feuilles <- c(sous_feuilles, 2*l+1)
Y[[2*l+1]] <- tree$Y_pred[[2*l+1]]}
}
noeuds_courants <- courant_prime
N <-p
}
}
if (length(noeuds_courants1)==0) {sous_feuilles <- c(2*t, 2*t+1)}
## C'est maintenant que ça devient coton :::
# Il faut récupérer les id des gens qui sont
s_feuilles <- NULL
s_id <- NULL
s_time <- NULL
s_Y <- NULL
for(f in unique(sous_feuilles)){
w <- which(tree$feuilles==f)
s_feuilles <- c(s_feuilles, tree$feuilles[w])
s_id <- c(s_id, tree$Y$id[w])
if (tree$Y$type=="curve"){
s_time <- c(s_time,tree$Y$time[w])
}
#s_time <- c(s_time, tree$time[w])
if (tree$Y$type=="shape" || tree$Y$type=="image") s_Y <- c(s_Y,w)
else s_Y <- c(s_Y, tree$Y$Y[w])
}
if (tree$Y$type=="shape" || tree$Y$type=="image") s_Y <- tree$Y$Y[,,s_Y,drop=FALSE]
#### il faut maintenant calculer l'impurete de la branche ainsi que celle du noeud t
#### impurete dans le noeud racine :::
impurity_racine <- tree$hist_imp_nodes[which(tree$hist_imp_nodes[,1]==racine),2]
n_racine <- tree$hist_imp_nodes[which(tree$hist_imp_nodes[,1]==racine),3]
n_base <- tree$hist_imp_nodes[1,3]
impurity_racine <- impurity_racine*(n_racine/n_base)
impurity_T <- 0
for (i in unique(s_feuilles)){
w <- which(tree$hist_imp_nodes[,1]==i)
prop <- tree$hist_imp_nodes[w,3]/n_base
impurity_T <- impurity_T + tree$hist_imp_nodes[w,2]*prop
}
if (tree$Y$type=="curve"){
sous_Y <- list(type=tree$Y$type, Y=s_Y, id = s_id, time=s_time)
}
else sous_Y <- list(type=tree$Y$type, Y=s_Y, id = s_id)
return(list(feuilles=s_feuilles, V_split = sous_split, hist_nodes=hist_nodes, Y=sous_Y, impurity_T = impurity_T, impurity_racine = impurity_racine, n_racine=n_racine, Y_pred=Y))
}
################################ On passe au lourd de chez lourd ########################################
noeuds_deg <- function(tree){
noeuds <- as.numeric(as.character(tree$V_split$num_noeud))
deg <- NULL
alpha <- rep()
mat_pen <- matrix(0, length(noeuds), 5)
mat_pen[,1] <- noeuds
for (t in noeuds){
b <- branche(tree,t) ### on recupère la branche associee à t
if (length(unique(b$feuilles))>1){
mat_pen[which(noeuds==t), 2] <- b$impurity_racine
mat_pen[which(noeuds==t), 3] <- b$impurity_T
mat_pen[which(noeuds==t), 4] <- length(unique(b$feuilles))
mat_pen[which(noeuds==t), 5] <- (b$impurity_racine-b$impurity_T)/(length(unique(b$feuilles))-1)}
#pen <- mat_pen[which(noeuds==t), 5]
#err <- b$impurity_T + pen*length(unique(b$feuilles)) - b$impurity_racine - pen
#print(err)
}
alpha <- min(mat_pen[,5])
err <- rep(0, length(noeuds))
for (i in  1:dim(mat_pen)[1]){
err[i] <- round(mat_pen[i,3] + alpha*mat_pen[i,4] - mat_pen[i,2] - alpha, 5)
if (err[i]==0){
deg <- rbind(deg, c(mat_pen[i,1], alpha))
}
}
return(deg)
}
### Ok donc on est capable de trouver les noeuds à tuer ::::: On fait l'elagage
elagage <- function(tree){
t_feuilles <- NULL
t_id <- NULL
t_time <- NULL
t_split <- NULL
t_hist <- NULL
t_Y <- tree$Y
tree_courant <- tree
nb_feuilles <- length(unique(tree$feuilles))
n_max <- nb_feuilles
courant <- 2
TREES <- list()
TREES[[1]] <- tree
##### il faut aussi trouver les d?coupe superficielles :::: on garde un historique des d?coupes :::::
while(nb_feuilles >1){
deg <- noeuds_deg(tree_courant)
if (dim(deg)[1]>1) deg <- apply(deg, 2, sort, decreasing=TRUE)
t_feuilles_courant <- tree_courant$feuilles
for (t in deg[,1]){
b <- branche(tree_courant, t)
feuilles_b <- unique(b$feuilles)
w_feuilles <- NULL
for (f in feuilles_b ){
w_feuilles <- c(w_feuilles, which(tree_courant$feuilles==f))
}
t_feuilles_courant[w_feuilles] <- t
#### il faut maintenant retirer toute la branche de t
nodes <- as.numeric(as.character(b$V_split[,2]))
w_nodes <- NULL
for (node in nodes){
w_nodes <- c(w_nodes, which(tree_courant$V_split[,2]==node))
}
t_split_courant <- tree_courant$V_split[-w_nodes,, drop = FALSE]
##### il faut alors recalculer l'importance dans les feuilles
tree_courant <- list(feuilles=t_feuilles_courant, V_split = t_split_courant,hist_nodes=tree$hist_nodes, Y=tree$Y, hist_imp_nodes=tree$hist_imp_nodes, Y_pred = tree$Y_pred, Alpha=unique(deg[,2]))
TREES[[courant]] <- tree_courant
}
courant <- courant+1
nb_feuilles <- length(unique(tree_courant$feuilles))
}
return(TREES)
}
### On passe à la fonction qui fâche ::::
FrechetTree <- function(Curve=NULL,Scalar=NULL,Factor=NULL,Y,timeScale=0.1, ...){
### Il faut normaliser les éléments des formes ::
if (Y$type=="shape"){
Y$Y <- gpagen(Y$Y,print.progress = FALSE)$coords
}
TMAX <- Tmax(Curve=Curve,Scalar = Scalar,Factor=Factor, Shape=NULL,Image=NULL,Y,timeScale = timeScale)
if (Y$type=="image" || Y$type=="shape") dime <- dim(Y$Y)[1:2]
elag_max <- elagage(TMAX)
ALPHA <- rep(NA, length(elag_max))
for (i in 1:length(ALPHA)){
ALPHA[i] <- elag_max[[i]]$Alpha
}
#### on transforme le tout en beta
beta <- rep(NA, length(ALPHA))
beta[length(ALPHA)] <- ALPHA[length(ALPHA)]
for (i in 1:(length(ALPHA)-1)){
beta[i] <- sqrt(abs(ALPHA[i]*ALPHA[i+1]))
}
#### Il faut faire faire les sous ensemble de validation crois?e::::
ELAG <- list()
n_folds <- 10
VC <- sample(rep(1:n_folds, length.out= length(unique(Y$id))))
tmax <- list()
APP <- list()
err <- matrix(0, length(beta), n_folds)
Scalar.app <- Scalar
Curve.app <- Curve
Factor.app <- Factor
Scalar.val <- NULL
Factor.val <- NULL
Curve.val <- NULL
for (p in 1:n_folds){
app <- unique(Y$id)[which(VC!=p)] ### on r?cup?re les identifiants
w <- NULL
wCurve <- NULL
wScalar <- NULL
wFactor <- NULL
for (a in app){
w <- c(w, which(Y$id==a))
if (is.null(Scalar)!=TRUE) wScalar <- c(wScalar, which(Scalar$id==a))
if (is.null(Factor)!=TRUE) wFactor <- c(wFactor, which(Factor$id==a))
if (is.null(Curve)!=TRUE) wCurve <- c(wCurve, which(Curve$id==a))
}
APP[[p]] <- w
### On prend les éléments d'apprentissage maintenant :::
if (is.null(Scalar)!=TRUE){
Scalar.app <- list(X=Scalar$X[wScalar,,drop=FALSE], id=Scalar$id[wScalar])
Scalar.val <- list(type="scalar",X=Scalar$X[-wScalar,,drop=FALSE], id=Scalar$id[-wScalar])
}
if (is.null(Factor)!=TRUE){
Factor.app <- list(X=Factor$X[wFactor,,drop=FALSE], id=Factor$id[wFactor])
Factor.val <- list(type="factor",X=Factor$X[-wFactor,,drop=FALSE], id=Factor$id[-wFactor])
}
if (is.null(Curve)!=TRUE){
Curve.app <- list(X=Curve$X[wCurve,,drop=FALSE], id=Curve$id[wCurve], time=Curve$time[wCurve])
Curve.val <- list(type="curve",X=Curve$X[-wCurve,,drop=FALSE], id=Curve$id[-wCurve], time=Curve$time[-wCurve])
}
if (Y$type=="curve"){
Y.app <- list(type="curve",Y=Y$Y[w],id=Y$id[w],time=Y$time[w])
Y.val <- list(type="curve",Y=Y$Y[-w],id=Y$id[-w],time=Y$time[-w])
}
if (Y$type=="factor" || Y$type=="scalar"){
Y.app <- list(type=Y$type,Y=Y$Y[w],id=Y$id[w],time=Y$time[w])
Y.val <- list(type=Y$type,Y=Y$Y[-w],id=Y$id[-w],time=Y$time[-w])
}
if (Y$type=="shape" || Y$type=="image"){
Y.app <- list(type=Y$type,Y=Y$Y[,,w],id=Y$id[w])
Y.val <- list(type=Y$type,Y=Y$Y[,, -w],id=Y$id[-w])
}
tmax[[p]] <- Tmax(Curve = Curve.app,Scalar = Scalar.app,Factor = Factor.app,Y=Y.app, timeScale = timeScale)
ELAG[[p]] <- elagage(tmax[[p]])
pen <- rep(NA,length(ELAG[[p]]))
#pen[length(ELAG[[p]])] <- ELAG[[p]][[length(ELAG[[p]])]]$Alpha
for (l in 1:length(pen)){
pen[l] <- ELAG[[p]][[l]]$Alpha
}
for (k in 1:length(beta)){
sous_arbre <- ELAG[[p]][[which.min(abs(pen-beta[k]))]]
where <- pred.FT(sous_arbre,Curve = Curve.val,Scalar=Scalar.val,Factor = Factor.val,timeScale = timeScale) #### on doit trouver les feuilles de pr?diction :::
##### il nous faut maintenant pr?dire les diff?rentes courbes ::::
err_courant <- rep(0, length(where))
for (j in 1:length(where)){
ww <- which(Y.val$id == unique(Y.val$id)[j])
#mean_courant <- DouglasPeuckerEpsilon(sous_arbre$Y_curves[[where[j]]][,1],sous_arbre$Y_curves[[where[j]]][,2], 0.01)
## On regarde si on a bien une sortie qui est une courbe:
if (Y$type=="curve") err_courant[j] <-  kmlShape::distFrechet(Y.val$time[ww], Y.val$Y[ww],sous_arbre$Y_pred[[where[j]]][,1], sous_arbre$Y_pred[[where[j]]][,2])
if (Y$type=="scalar") err_courant[j] <- (Y.val$Y[ww]-where[j])^2
if (Y$type=="factor") err_courant[j] <- 1*(Y.val$Y[ww]==where[j])
if (Y$type=="image") err_courant[j] <- rbase.pdist2(riemfactory(Y.val$Y[,,ww, drop=FALSE]),riemfactory(array(sous_arbre$Y_pred[[where[j]]],dim=c(dime[1],dime[2],1))))
if (Y$type=="shape") err_courant[j] <- ShapeDist(array(sous_arbre$Y_pred[[where[j]]],dim=c(dime[1],dime[2],1)),Y.val$Y[,,ww])
}
err[k,p] <- mean(err_courant)
}
}
SD <- apply(err, 1, "sd")
err_M <- apply(err, 1, "mean")
### On prend le meilleur mod?le
seuil <- min(err_M) + SD[which.min(err_M)]
### il faut s?lectionner le meilleur arbre
optimal.tree <- which.min(abs(err_M<=seuil)) #err_M[which(err_M<=seuil)]
beta.opt <- beta[optimal.tree]
final_tree <- elag_max[[optimal.tree]]
#### On va s?lectionner l'arbre optimal pour chaque ensemble d'apprentissage puis calculer l'importance des variables sur ceux-ci::
#Importance <- matrix(0, n_folds, dim(X)[2])
err_arbres_select <- rep(NA, n_folds)
for (k in 1:n_folds){
### on r?cup?re les ?l?ments de validation::::
#X.val <- X[-APP[[k]],]
#Y.val <- Y[-APP[[k]]]
#time.val <- time[-APP[[k]]]
#id.val <- id[-APP[[k]]]
pen <- rep(NA,length(ELAG[[k]]))
for (l in 1:length(pen)){
pen[l] <- ELAG[[k]][[l]]$Alpha
}
}
m_leafs <- max(unique(final_tree$feuilles))
return(list(feuilles = final_tree$feuilles, V_split=final_tree$V_split, hist_nodes=final_tree$hist_nodes[1:m_leafs], Y_pred=final_tree$Y_pred[1:m_leafs], err_elag = err_M, seuil=seuil, Y=Y))
}
ft <- FrechetTreeCurve = Curve, Y=data$Y)
ft <- FrechetTree(Curve = Curve, Y=data$Y)
ft$V_split
plot(ft$err_elag)
lines(rep(ft$seuil, length(ft$err_elag)), col=3)
data <- DataGenCurves5(n=100,disp = 0.1,Vshift = 0.01,Hshift = 0.1,scalar.perturb = 2, Nshape = 50,affiche=TRUE)
ft <- FrechetTree(Curve = Curve, Y=data$Y)
library(FrechForest)
### Je sais pas trop ce qu'il contient en plus ici
library(tgp)
n=100
data.bool <- fried.bool(n)
Scalar <- list(type="scalar",X=data.bool[,1:10], id=c(1:n))
Factor <- list(type="factor",X=data.bool[,11:13],id=c(1:n))
Y <- list(type="scalar",Y=data.bool$Y, id=c(1:n))
rf <- randomForest(data.bool[,1:13],data.bool$Y)
frf <- FrechForest(Scalar = Scalar,Factor=Factor, Y=Y, ncores=4, ntree=100, ERT=TRUE)
frf$rsq
mean(frf$OOB.err)
rf
library(randomForest)
rf <- randomForest(data.bool[,1:13],data.bool$Y)
rf
frf <- FrechForest(Scalar = Scalar,Factor=Factor, Y=Y, ncores=4, ntree=100)
frf$rsq
mean(frf$OOB.err)
rf
frf <- FrechForest(Scalar = Scalar,Factor=Factor, Y=Y, ncores=4, ntree=300)
rf
frf$rsq
mean(frf$OOB.err)
library(tgp)
library(rpart)
library(tgp)
n=100
data <- friedman.1.data(n)
tree <- rpart(Y~., data[,-12])
tree
plot(tree)
text(text)
text(tree)
plot(tree)
text(tree)
x_prime <- c(0.2,0.1,rep(0,8))
x_prime <- c(0.2,0.1,rep(0,8))
x_prime <- as.data.frame(x_prime)
names(x_prime) <- names(data)[1:10]
x_rpime
x_prime
x_prime <- matrix(c(0.2,0.1,rep(0,8)),1,10)
x_prime <- as.data.frame(x_prime)
names(x_prime) <- names(data)[1:10]
x_prime
pred <- predict(tree, x_prime)
pred
n=100
data <- friedman.1.data(n)
tree <- rpart(Y~., data[,-12])
plot(tree)
text(tree)
x_prime <- matrix(rep(0,10),1,10)
x_prime[4] <- 0.2
x_prime[2] <- 0.1
x_prime <- as.data.frame(x_prime)
names(x_prime) <- names(data)[1:10]
pred <- predict(tree, x_prime)
pred
summary(tree)
tree
