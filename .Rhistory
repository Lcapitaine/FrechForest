Data <- data.frame(X.app,time.app, id.app, Y.app)
### We put the learning sample to the right format for FDboost method
Y.app.FD <- matrix(Y.app, byrow = TRUE, nrow = n-n.test)
X1.app.FD <- scale(matrix(X.app$X1, byrow = TRUE, nrow = n-n.test), scale = FALSE)
X2.app.FD <- scale(matrix(X.app$X2, byrow = TRUE, nrow = n-n.test), scale = FALSE)
DataMatFD  <- list(Y = Y.app.FD, X1 = X1.app.FD, X2 = X2.app.FD, time = sort(unique(time.app)))
### We put the test sample to the right format for FDboost method
Y.test.FD <- matrix(Y.test, byrow = TRUE, nrow = n.test)
X1.test.FD <- scale(matrix(X.test$X1, byrow = TRUE, nrow = n.test), scale = FALSE)
X2.test.FD <- scale(matrix(X.test$X2, byrow = TRUE, nrow = n.test), scale = FALSE)
DataMatFD.test  <- list(Y = Y.test.FD, X1 = X1.test.FD, X2 = X2.test.FD, time = sort(unique(time.test)))
### Now we run the methods on the learning sample
FD <- FDboost(Y ~ bsignal(X1, s = time) + bsignal(X2, s = time),timeformula = ~ bbs(time, df = 3), data = DataMatFD )
opti <- mstop(cvrisk(FD, folds = cvLong(id = FD$id, weights = model.weights(FD)),grid = 1:1000))
FD <- FDboost(Y ~ bsignal(X1, s = time) + bsignal(X2, s = time),timeformula = ~ bbs(time, df = 3), data = DataMatFD,control= boost_control(mstop = opti))
ftree <- FrechetTree(Curve = courbes.app, Y=Y2.app, ncores=4)
cart <- rpart(Y.app~.,data=Data)
rf <- randomForest(Data[,-5],Y.app)
# Note that the Frechet random forests method is parallelized
# We used 8 cores in our simulations
frf <- FrechForest(Curve=courbes.app,Y=Y2.app,ncores = 8, imp=FALSE)
ERfrf <- FrechForest(Curve=courbes.app,Y=Y2.app,ncores = 8, imp=FALSE, ERT = TRUE, ntry = 3)
LMEM <- lmer(Y.app~ X1+X2 + (1| time.app), data=Data)
### And we predict the test sample
Data.test <- data.frame(X.test, time.test, id.test)
names(Data.test) <- names(Data)[1:4]
pred.cart <- predict(cart,Data.test)
pred.ftree <- pred.FT(ftree,Curve=list(type="curve",X=courbes.test$X, time=courbes.test$time, id=courbes.test$id))
pred.rf <- predict(rf, Data.test)
pred.frf <- predict(frf, Curve=courbes.test)
pred.ERfrf <- predict(ERfrf, Curve=courbes.test)
pred.LMEM <- predict(LMEM, Data.test)
pred.FD <- predict(FD, newdata = DataMatFD.test) #prediction with FDboost
pred.ERfrf
err.FD.euclidien <- rep(NA,n.test)
err.FD.frech <- rep(NA,n.test)
err.LMEM.euclidien <- rep(NA,n.test)
err.LMEM.frech <- rep(NA,n.test)
err.cart.euclidien <- rep(NA,n.test)
err.cart.frech <- rep(NA,n.test)
err.rf.euclidien <- rep(NA,n.test)
err.rf.frech <- rep(NA,n.test)
err.ftree.euclidien <- rep(NA,n.test)
err.ftree.frech <- rep(NA,n.test)
err.FRF.euclidien <- rep(NA,n.test)
err.FRF.frech <- rep(NA,n.test)
err.ERFRF.euclidien <- rep(NA,n.test)
err.ERFRF.frech <- rep(NA,n.test)
### We compute the errors predictions on the test sample
for (i in 1:length(test)){ #We look at the error prediction for each predicted curve
w <- which(id.test==test[i])
err.FD.euclidien[i] <- mean((Y.test[w]-pred.FD[i,])^2)
err.FD.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w],pred.FD[i,])^2
err.LMEM.euclidien[i] <- mean((Y.test[w] - pred.LMEM[w])^2)
err.LMEM.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.LMEM[w])^2
err.cart.euclidien[i] <- mean((Y.test[w]- pred.cart[w])^2)
err.cart.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.cart[w])^2
err.rf.euclidien[i] <- mean((Y.test[w]- pred.rf[w])^2)
err.rf.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.rf[w])^2
leaf <- pred.ftree[which(pred.ftree[,1]==test[i]),2]
curve.ftree <- ftree$Y_curves[[leaf]]
curve.frf <- pred.frf[which(pred.frf[,3]==test[i]),1:2]
curve.erfrf <- pred.ERfrf[which(pred.ERfrf[,3]==test[i]),1:2]
# The function curve.reduc.times is used to reduce the predicted times for
# the Frechet Trees and Frechet random forests methods
# because of the nature of the approximation of the Frechet mean,
# The curves predicted with the Frechet methodes contain much more observation times than the ones obtained with the other methods
new.curve <- curve.reduc.times(curve.ftree$times, curve.ftree$traj, time.test[w])
new.curve2 <- curve.reduc.times(curve.frf[,1], curve.frf[,2], time.test[w])
new.curve.erfrf <- curve.reduc.times(curve.erfrf[,1], curve.erfrf[,2], time.test[w])
err.ftree.euclidien[i] <- mean((Y.test[w]-new.curve[,2])^2)
err.ftree.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve[,1], new.curve[,2])^2
err.FRF.euclidien[i] <- mean((Y.test[w]-new.curve2[,2])^2)
err.FRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve2[,1], new.curve2[,2])^2
err.ERFRF.euclidien[i] <- mean((Y.test[w]-new.curve.erfrf[,2])^2)
err.ERFRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve.erfrf[,1], new.curve.erfrf[,2])^2
}
pred.ftree
leaf <- pred.ftree[i]
curve.ftree <- ftree$Y_curves[[leaf]]
curve.frf <- pred.frf[which(pred.frf[,3]==test[i]),1:2]
curve.erfrf <- pred.ERfrf[which(pred.ERfrf[,3]==test[i]),1:2]
# The function curve.reduc.times is used to reduce the predicted times for
# the Frechet Trees and Frechet random forests methods
# because of the nature of the approximation of the Frechet mean,
# The curves predicted with the Frechet methodes contain much more observation times than the ones obtained with the other methods
new.curve <- curve.reduc.times(curve.ftree$times, curve.ftree$traj, time.test[w])
curve.ftree
leaf
pred.ftree
ftree$feuilles
ftree$Y_pred
ftree$Y_pred[[13]]
ftree$Y_pred[[13]]
leaf
class(leaf)
curve.ftree <- ftree$Y_curves[[leaf]]
curve.ftree
curve.ftree <- ftree$Y_pred[[leaf]]
curve.ftree
curve.frf <- pred.frf[which(pred.frf[,3]==test[i]),1:2]
curve.erfrf <- pred.ERfrf[which(pred.ERfrf[,3]==test[i]),1:2]
# The function curve.reduc.times is used to reduce the predicted times for
# the Frechet Trees and Frechet random forests methods
# because of the nature of the approximation of the Frechet mean,
# The curves predicted with the Frechet methodes contain much more observation times than the ones obtained with the other methods
new.curve <- curve.reduc.times(curve.ftree$times, curve.ftree$traj, time.test[w])
new.curve2 <- curve.reduc.times(curve.frf[,1], curve.frf[,2], time.test[w])
new.curve.erfrf <- curve.reduc.times(curve.erfrf[,1], curve.erfrf[,2], time.test[w])
err.ftree.euclidien[i] <- mean((Y.test[w]-new.curve[,2])^2)
err.ftree.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve[,1], new.curve[,2])^2
err.FRF.euclidien[i] <- mean((Y.test[w]-new.curve2[,2])^2)
err.FRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve2[,1], new.curve2[,2])^2
err.ERFRF.euclidien[i] <- mean((Y.test[w]-new.curve.erfrf[,2])^2)
err.ERFRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve.erfrf[,1], new.curve.erfrf[,2])^2
### We compute the errors predictions on the test sample
for (i in 1:length(test)){ #We look at the error prediction for each predicted curve
w <- which(id.test==test[i])
err.FD.euclidien[i] <- mean((Y.test[w]-pred.FD[i,])^2)
err.FD.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w],pred.FD[i,])^2
err.LMEM.euclidien[i] <- mean((Y.test[w] - pred.LMEM[w])^2)
err.LMEM.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.LMEM[w])^2
err.cart.euclidien[i] <- mean((Y.test[w]- pred.cart[w])^2)
err.cart.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.cart[w])^2
err.rf.euclidien[i] <- mean((Y.test[w]- pred.rf[w])^2)
err.rf.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.rf[w])^2
leaf <- pred.ftree[i]
curve.ftree <- ftree$Y_pred[[leaf]]
curve.frf <- pred.frf[which(pred.frf[,3]==test[i]),1:2]
curve.erfrf <- pred.ERfrf[which(pred.ERfrf[,3]==test[i]),1:2]
# The function curve.reduc.times is used to reduce the predicted times for
# the Frechet Trees and Frechet random forests methods
# because of the nature of the approximation of the Frechet mean,
# The curves predicted with the Frechet methodes contain much more observation times than the ones obtained with the other methods
new.curve <- curve.reduc.times(curve.ftree$times, curve.ftree$traj, time.test[w])
new.curve2 <- curve.reduc.times(curve.frf[,1], curve.frf[,2], time.test[w])
new.curve.erfrf <- curve.reduc.times(curve.erfrf[,1], curve.erfrf[,2], time.test[w])
err.ftree.euclidien[i] <- mean((Y.test[w]-new.curve[,2])^2)
err.ftree.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve[,1], new.curve[,2])^2
err.FRF.euclidien[i] <- mean((Y.test[w]-new.curve2[,2])^2)
err.FRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve2[,1], new.curve2[,2])^2
err.ERFRF.euclidien[i] <- mean((Y.test[w]-new.curve.erfrf[,2])^2)
err.ERFRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve.erfrf[,1], new.curve.erfrf[,2])^2
}
err.FD.euclidien
err.ftree.euclidien
mean(err.FD.euclidien)
mean(err.ftree.euclidien)
mean(err.FRF.euclidien)
mean(err.ERFRF.euclidien)
mean(err.FRF.frech)
mean(err.FD.frech)
mean(err.ERFRF.frech)
setwd("~/Documents/Curta")
#Load the packages :
library(FrechForest)
help("FrechForest") # To check the informations about the different functions
library(randomForest)
library(rpart)
library(kmlShape)
library(lme4)
library(GPFDA)
library(FDboost)
library(latex2exp)
debut <- Sys.time()
# This function will simulate dataset according to the scheme of simulations in the paper :
DataGenCurves2 <- function(n, disp){
# n is the number of curves
# disp is the variance of the beta parameter
time <- seq(0,1,0.05) # Measurement times for inputs and output
id <- NULL # Id of the different curves
for (i in 1:n){
id <- c(id,rep(i,length(time)))
}
G1 <- 1*(runif(n)<0.5)  # Groupes of trajectories for the first input variable
G2 <- 1*(runif(n)<0.5)  # Groupes of trajectories for the second input variable
# Define the typical temporal behavior functions f.,. for the input variables :
f11 <- function(t){
return(0.5*t+0.1*sin(6*t))
}
f12 <- function(t){
return(0.3-0.7*(t-0.45)^2)
}
f21 <- function(t){
return(2*(t-0.5)^2 - t*0.3)
}
f22 <- function(t){
return(0.2 -0.3*t + 0.1*cos(8*t))
}
# Simulation of the Input Variables :
X1 <- NULL
X2 <- NULL
beta <- rnorm(n,1,disp) # Dilatation terms
for (i in 1:n){
X1 <- c(X1, beta[i]*((G1[i]==1)*f11(time)+(G1[i]==0)*f12(time)))
X2 <- c(X2, beta[i]*((G2[i]==1)*f21(time)+(G2[i]==0)*f22(time)))
}
X1 <- X1+ rnorm(length(X1), 0,0.02) # We add some noise
X2 <- X2+ rnorm(length(X2), 0,0.02) # We add some noise
X <- data.frame(X1,X2) # Data matrix
# Define the timepical temporal behavior functions g.,. for the Output :
g11 <- function(t){
return(t+ 0.3*sin(10*(t+1)))
}
g12<- function(t){
return(t+2*(t-0.7)^2)
}
g21 <- function(t){
return(1.5*exp(-(t-0.5)^2/0.5)- 0.1*(t+1)*cos(10*t))
}
g22 <- function(t){
return(log(13*abs(t+0.2))/(1+t))
}
# Output simulation :
Y <- NULL
for (i in 1:n){
Y <- c(Y, beta[i]*((G1[i]==1 & G2[i]==0)*(g11(time))+ (G1[i]==1 & G2[i]==1)*(g12(time )) + (G1[i]==0 & G2[i]==1)*(g21(time)) + (G1[i]==0 & G2[i]==0)*(g22(time))))
}
Y <- Y+ rnorm(length(Y), 0, 0.05) # We add some noise
return(list(X=X,Y=Y,time=rep(time,n), id=id))
}
prop <- 0.2
n <- 100
n.test <- floor(n*prop)
data <- DataGenCurves2(n,0.3) # Simulate data according to the first scenario
test <- sample(unique(data$id), n.test) # We pull the test sample
w.test  <- NULL
for (i in 1:length(test)){
w.test <- c(w.test, which(data$id==test[i]))
}
id.app <- data$id[-w.test]
X.app <- data$X[-w.test, ]
Y.app <- data$Y[-w.test]
time.app <- data$time[-w.test]
id.test <- data$id[w.test]
X.test <- data$X[w.test,]
Y.test <- data$Y[w.test]
time.test <- data$time[w.test]
# On va mettre les courbes de test et d'apprentissage:
courbes.app <- list(X=X.app,time=time.app,id=id.app)
courbes.test <- list(X=X.test, time=time.test, id=id.test)
Y2.app <- list(type="curve",Y=Y.app, time=time.app, id=id.app)
Y2.test <- list(type="curve",Y=Y.test, time=time.test, id=id.test)
#
Data <- data.frame(X.app,time.app, id.app, Y.app)
### We put the learning sample to the right format for FDboost method
Y.app.FD <- matrix(Y.app, byrow = TRUE, nrow = n-n.test)
X1.app.FD <- scale(matrix(X.app$X1, byrow = TRUE, nrow = n-n.test), scale = FALSE)
X2.app.FD <- scale(matrix(X.app$X2, byrow = TRUE, nrow = n-n.test), scale = FALSE)
DataMatFD  <- list(Y = Y.app.FD, X1 = X1.app.FD, X2 = X2.app.FD, time = sort(unique(time.app)))
### We put the test sample to the right format for FDboost method
Y.test.FD <- matrix(Y.test, byrow = TRUE, nrow = n.test)
X1.test.FD <- scale(matrix(X.test$X1, byrow = TRUE, nrow = n.test), scale = FALSE)
X2.test.FD <- scale(matrix(X.test$X2, byrow = TRUE, nrow = n.test), scale = FALSE)
DataMatFD.test  <- list(Y = Y.test.FD, X1 = X1.test.FD, X2 = X2.test.FD, time = sort(unique(time.test)))
### Now we run the methods on the learning sample
FD <- FDboost(Y ~ bsignal(X1, s = time) + bsignal(X2, s = time),timeformula = ~ bbs(time, df = 3), data = DataMatFD )
opti <- mstop(cvrisk(FD, folds = cvLong(id = FD$id, weights = model.weights(FD)),grid = 1:1000))
FD <- FDboost(Y ~ bsignal(X1, s = time) + bsignal(X2, s = time),timeformula = ~ bbs(time, df = 3), data = DataMatFD,control= boost_control(mstop = opti))
ftree <- FrechetTree(Curve = courbes.app, Y=Y2.app, ncores=4)
cart <- rpart(Y.app~.,data=Data)
rf <- randomForest(Data[,-5],Y.app)
# Note that the Frechet random forests method is parallelized
# We used 8 cores in our simulations
frf <- FrechForest(Curve=courbes.app,Y=Y2.app,ncores = 8, imp=FALSE)
ERfrf <- FrechForest(Curve=courbes.app,Y=Y2.app,ncores = 8, imp=FALSE, ERT = TRUE, ntry = 3)
LMEM <- lmer(Y.app~ X1+X2 + (1| time.app), data=Data)
### And we predict the test sample
Data.test <- data.frame(X.test, time.test, id.test)
names(Data.test) <- names(Data)[1:4]
pred.cart <- predict(cart,Data.test)
pred.ftree <- pred.FT(ftree,Curve=list(type="curve",X=courbes.test$X, time=courbes.test$time, id=courbes.test$id))
pred.rf <- predict(rf, Data.test)
pred.frf <- predict(frf, Curve=courbes.test)
pred.ERfrf <- predict(ERfrf, Curve=courbes.test)
pred.LMEM <- predict(LMEM, Data.test)
pred.FD <- predict(FD, newdata = DataMatFD.test) #prediction with FDboost
err.FD.euclidien <- rep(NA,n.test)
err.FD.frech <- rep(NA,n.test)
err.LMEM.euclidien <- rep(NA,n.test)
err.LMEM.frech <- rep(NA,n.test)
err.cart.euclidien <- rep(NA,n.test)
err.cart.frech <- rep(NA,n.test)
err.rf.euclidien <- rep(NA,n.test)
err.rf.frech <- rep(NA,n.test)
err.ftree.euclidien <- rep(NA,n.test)
err.ftree.frech <- rep(NA,n.test)
err.FRF.euclidien <- rep(NA,n.test)
err.FRF.frech <- rep(NA,n.test)
err.ERFRF.euclidien <- rep(NA,n.test)
err.ERFRF.frech <- rep(NA,n.test)
### We compute the errors predictions on the test sample
for (i in 1:length(test)){ #We look at the error prediction for each predicted curve
w <- which(id.test==test[i])
err.FD.euclidien[i] <- mean((Y.test[w]-pred.FD[i,])^2)
err.FD.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w],pred.FD[i,])^2
err.LMEM.euclidien[i] <- mean((Y.test[w] - pred.LMEM[w])^2)
err.LMEM.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.LMEM[w])^2
err.cart.euclidien[i] <- mean((Y.test[w]- pred.cart[w])^2)
err.cart.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.cart[w])^2
err.rf.euclidien[i] <- mean((Y.test[w]- pred.rf[w])^2)
err.rf.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.rf[w])^2
leaf <- pred.ftree[i]
curve.ftree <- ftree$Y_pred[[leaf]]
curve.frf <- pred.frf[which(pred.frf[,3]==test[i]),1:2]
curve.erfrf <- pred.ERfrf[which(pred.ERfrf[,3]==test[i]),1:2]
# The function curve.reduc.times is used to reduce the predicted times for
# the Frechet Trees and Frechet random forests methods
# because of the nature of the approximation of the Frechet mean,
# The curves predicted with the Frechet methodes contain much more observation times than the ones obtained with the other methods
new.curve <- curve.reduc.times(curve.ftree$times, curve.ftree$traj, time.test[w])
new.curve2 <- curve.reduc.times(curve.frf[,1], curve.frf[,2], time.test[w])
new.curve.erfrf <- curve.reduc.times(curve.erfrf[,1], curve.erfrf[,2], time.test[w])
err.ftree.euclidien[i] <- mean((Y.test[w]-new.curve[,2])^2)
err.ftree.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve[,1], new.curve[,2])^2
err.FRF.euclidien[i] <- mean((Y.test[w]-new.curve2[,2])^2)
err.FRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve2[,1], new.curve2[,2])^2
err.ERFRF.euclidien[i] <- mean((Y.test[w]-new.curve.erfrf[,2])^2)
err.ERFRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve.erfrf[,1], new.curve.erfrf[,2])^2
}
tmps <- Sys.time()-debut
setwd("~/Documents/Curta")
#Load the packages :
library(FrechForest)
help("FrechForest") # To check the informations about the different functions
library(randomForest)
library(rpart)
library(kmlShape)
library(lme4)
library(GPFDA)
library(FDboost)
library(latex2exp)
debut <- Sys.time()
# This function will simulate dataset according to the scheme of simulations in the paper :
DataGenCurves2 <- function(n, disp){
# n is the number of curves
# disp is the variance of the beta parameter
time <- seq(0,1,0.05) # Measurement times for inputs and output
id <- NULL # Id of the different curves
for (i in 1:n){
id <- c(id,rep(i,length(time)))
}
G1 <- 1*(runif(n)<0.5)  # Groupes of trajectories for the first input variable
G2 <- 1*(runif(n)<0.5)  # Groupes of trajectories for the second input variable
# Define the typical temporal behavior functions f.,. for the input variables :
f11 <- function(t){
return(0.5*t+0.1*sin(6*t))
}
f12 <- function(t){
return(0.3-0.7*(t-0.45)^2)
}
f21 <- function(t){
return(2*(t-0.5)^2 - t*0.3)
}
f22 <- function(t){
return(0.2 -0.3*t + 0.1*cos(8*t))
}
# Simulation of the Input Variables :
X1 <- NULL
X2 <- NULL
beta <- rnorm(n,1,disp) # Dilatation terms
for (i in 1:n){
X1 <- c(X1, beta[i]*((G1[i]==1)*f11(time)+(G1[i]==0)*f12(time)))
X2 <- c(X2, beta[i]*((G2[i]==1)*f21(time)+(G2[i]==0)*f22(time)))
}
X1 <- X1+ rnorm(length(X1), 0,0.02) # We add some noise
X2 <- X2+ rnorm(length(X2), 0,0.02) # We add some noise
X <- data.frame(X1,X2) # Data matrix
# Define the timepical temporal behavior functions g.,. for the Output :
g11 <- function(t){
return(t+ 0.3*sin(10*(t+1)))
}
g12<- function(t){
return(t+2*(t-0.7)^2)
}
g21 <- function(t){
return(1.5*exp(-(t-0.5)^2/0.5)- 0.1*(t+1)*cos(10*t))
}
g22 <- function(t){
return(log(13*abs(t+0.2))/(1+t))
}
# Output simulation :
Y <- NULL
for (i in 1:n){
Y <- c(Y, beta[i]*((G1[i]==1 & G2[i]==0)*(g11(time))+ (G1[i]==1 & G2[i]==1)*(g12(time )) + (G1[i]==0 & G2[i]==1)*(g21(time)) + (G1[i]==0 & G2[i]==0)*(g22(time))))
}
Y <- Y+ rnorm(length(Y), 0, 0.05) # We add some noise
return(list(X=X,Y=Y,time=rep(time,n), id=id))
}
# This function will be used to evaluate the predicted curves to other times :
curve.reduc.times <- function(time.init , traj.init, time.new){
new.curve <- matrix(NA,length(time.new),2)
for (j in 1:length(time.new)){
w.time <- which.min(abs(time.new[j]-time.init))
if (time.init[w.time]==time.new[j]){
new.curve[j,] <- c(time.new[j], traj.init[w.time])
}
else {
t_g <- (time.new[j]>time.init[w.time])*(time.init[w.time]) + (time.new[j]<time.init[w.time])*(time.init[w.time-1])
t_d <- (time.new[j]<time.init[w.time])*(time.init[w.time]) + (time.new[j]>time.init[w.time])*(time.init[w.time+1])
Y_g <- (time.new[j]>time.init[w.time])*(traj.init[w.time]) + (time.new[j]<time.init[w.time])*(traj.init[w.time-1])
Y_d <- (time.new[j]<time.init[w.time])*(traj.init[w.time]) + (time.new[j]>time.init[w.time])*(traj.init[w.time+1])
d1 <- time.new[j]-t_g
d2 <- t_d - time.new[j]
new.curve[j,] <- c(time.new[j], (1 - (d1/(d1+d2)))*Y_g + (1 - (d2/(d1+d2)))*Y_d)
}
}
return(new.curve)
}
prop <- 0.2
n <- 100
n.test <- floor(n*prop)
data <- DataGenCurves2(n,0.3) # Simulate data according to the first scenario
test <- sample(unique(data$id), n.test) # We pull the test sample
w.test  <- NULL
for (i in 1:length(test)){
w.test <- c(w.test, which(data$id==test[i]))
}
id.app <- data$id[-w.test]
X.app <- data$X[-w.test, ]
Y.app <- data$Y[-w.test]
time.app <- data$time[-w.test]
id.test <- data$id[w.test]
X.test <- data$X[w.test,]
Y.test <- data$Y[w.test]
time.test <- data$time[w.test]
# On va mettre les courbes de test et d'apprentissage:
courbes.app <- list(X=X.app,time=time.app,id=id.app)
courbes.test <- list(X=X.test, time=time.test, id=id.test)
Y2.app <- list(type="curve",Y=Y.app, time=time.app, id=id.app)
Y2.test <- list(type="curve",Y=Y.test, time=time.test, id=id.test)
#
Data <- data.frame(X.app,time.app, id.app, Y.app)
### We put the learning sample to the right format for FDboost method
Y.app.FD <- matrix(Y.app, byrow = TRUE, nrow = n-n.test)
X1.app.FD <- scale(matrix(X.app$X1, byrow = TRUE, nrow = n-n.test), scale = FALSE)
X2.app.FD <- scale(matrix(X.app$X2, byrow = TRUE, nrow = n-n.test), scale = FALSE)
DataMatFD  <- list(Y = Y.app.FD, X1 = X1.app.FD, X2 = X2.app.FD, time = sort(unique(time.app)))
### We put the test sample to the right format for FDboost method
Y.test.FD <- matrix(Y.test, byrow = TRUE, nrow = n.test)
X1.test.FD <- scale(matrix(X.test$X1, byrow = TRUE, nrow = n.test), scale = FALSE)
X2.test.FD <- scale(matrix(X.test$X2, byrow = TRUE, nrow = n.test), scale = FALSE)
DataMatFD.test  <- list(Y = Y.test.FD, X1 = X1.test.FD, X2 = X2.test.FD, time = sort(unique(time.test)))
### Now we run the methods on the learning sample
FD <- FDboost(Y ~ bsignal(X1, s = time) + bsignal(X2, s = time),timeformula = ~ bbs(time, df = 3), data = DataMatFD )
opti <- mstop(cvrisk(FD, folds = cvLong(id = FD$id, weights = model.weights(FD)),grid = 1:1000))
FD <- FDboost(Y ~ bsignal(X1, s = time) + bsignal(X2, s = time),timeformula = ~ bbs(time, df = 3), data = DataMatFD,control= boost_control(mstop = opti))
ftree <- FrechetTree(Curve = courbes.app, Y=Y2.app, ncores=4)
cart <- rpart(Y.app~.,data=Data)
rf <- randomForest(Data[,-5],Y.app)
# Note that the Frechet random forests method is parallelized
# We used 8 cores in our simulations
frf <- FrechForest(Curve=courbes.app,Y=Y2.app,ncores = 8, imp=FALSE)
ERfrf <- FrechForest(Curve=courbes.app,Y=Y2.app,ncores = 8, imp=FALSE, ERT = TRUE, ntry = 3)
LMEM <- lmer(Y.app~ X1+X2 + (1| time.app), data=Data)
### And we predict the test sample
Data.test <- data.frame(X.test, time.test, id.test)
names(Data.test) <- names(Data)[1:4]
pred.cart <- predict(cart,Data.test)
pred.ftree <- pred.FT(ftree,Curve=list(type="curve",X=courbes.test$X, time=courbes.test$time, id=courbes.test$id))
pred.rf <- predict(rf, Data.test)
pred.frf <- predict(frf, Curve=courbes.test)
pred.ERfrf <- predict(ERfrf, Curve=courbes.test)
pred.LMEM <- predict(LMEM, Data.test)
pred.FD <- predict(FD, newdata = DataMatFD.test) #prediction with FDboost
err.FD.euclidien <- rep(NA,n.test)
err.FD.frech <- rep(NA,n.test)
err.LMEM.euclidien <- rep(NA,n.test)
err.LMEM.frech <- rep(NA,n.test)
err.cart.euclidien <- rep(NA,n.test)
err.cart.frech <- rep(NA,n.test)
err.rf.euclidien <- rep(NA,n.test)
err.rf.frech <- rep(NA,n.test)
err.ftree.euclidien <- rep(NA,n.test)
err.ftree.frech <- rep(NA,n.test)
err.FRF.euclidien <- rep(NA,n.test)
err.FRF.frech <- rep(NA,n.test)
err.ERFRF.euclidien <- rep(NA,n.test)
err.ERFRF.frech <- rep(NA,n.test)
### We compute the errors predictions on the test sample
for (i in 1:length(test)){ #We look at the error prediction for each predicted curve
w <- which(id.test==test[i])
err.FD.euclidien[i] <- mean((Y.test[w]-pred.FD[i,])^2)
err.FD.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w],pred.FD[i,])^2
err.LMEM.euclidien[i] <- mean((Y.test[w] - pred.LMEM[w])^2)
err.LMEM.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.LMEM[w])^2
err.cart.euclidien[i] <- mean((Y.test[w]- pred.cart[w])^2)
err.cart.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.cart[w])^2
err.rf.euclidien[i] <- mean((Y.test[w]- pred.rf[w])^2)
err.rf.frech[i] <- distFrechet(time.test[w],Y.test[w], time.test[w], pred.rf[w])^2
leaf <- pred.ftree[i]
curve.ftree <- ftree$Y_pred[[leaf]]
curve.frf <- pred.frf[which(pred.frf[,3]==test[i]),1:2]
curve.erfrf <- pred.ERfrf[which(pred.ERfrf[,3]==test[i]),1:2]
# The function curve.reduc.times is used to reduce the predicted times for
# the Frechet Trees and Frechet random forests methods
# because of the nature of the approximation of the Frechet mean,
# The curves predicted with the Frechet methodes contain much more observation times than the ones obtained with the other methods
new.curve <- curve.reduc.times(curve.ftree$times, curve.ftree$traj, time.test[w])
new.curve2 <- curve.reduc.times(curve.frf[,1], curve.frf[,2], time.test[w])
new.curve.erfrf <- curve.reduc.times(curve.erfrf[,1], curve.erfrf[,2], time.test[w])
err.ftree.euclidien[i] <- mean((Y.test[w]-new.curve[,2])^2)
err.ftree.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve[,1], new.curve[,2])^2
err.FRF.euclidien[i] <- mean((Y.test[w]-new.curve2[,2])^2)
err.FRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve2[,1], new.curve2[,2])^2
err.ERFRF.euclidien[i] <- mean((Y.test[w]-new.curve.erfrf[,2])^2)
err.ERFRF.frech[i] <- distFrechet(time.test[w],Y.test[w], new.curve.erfrf[,1], new.curve.erfrf[,2])^2
}
tmps <- Sys.time()-debut
tmps
err.ERFRF.euclidien
err.FRF.euclidien
